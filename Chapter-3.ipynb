{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Processing Pipelines\n\n# Internal Workings of doc = nlp('hello strings')\n# Built in pipeline components\n\n# token.tag, token.pos\n# token.dep, token.head, Doc.sents, Doc.noun_chunks\n# doc.ents, doc.ent_iob, doc.ent_type\n# doc.cats -> text classifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# from spacy.lang.en import English\nimport spacy\nnlp = spacy.load('en_core_web_lg')\n\nnlp.pipe_names","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['tagger', 'parser', 'ner']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp.pipeline","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fb6095782d0>),\n ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fb6083ecad0>),\n ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fb6083eca60>)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Adding custom components\n\n# def custom_component:\n    #do something here     \n#     return doc\n\n# nlp.add_pipe(custom_component)\n\n# add_pipe optional parameters first=True, last=True(default) , before='ner',after = 'ner'","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\n\n# Define the custom component\ndef length_component(doc):\n    # Get the doc's length\n    doc_length = len(doc)\n    print(f\"This document is {doc_length} tokens long.\")\n    # Return the doc\n    return doc\n\n\n# Load the small English model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Add the component first in the pipeline and print the pipe names\nnlp.add_pipe(length_component, first=True)\nprint(nlp.pipe_names)\n\n# Process a text\ndoc = nlp(\"This is a sentence.\")","execution_count":6,"outputs":[{"output_type":"stream","text":"['length_component', 'tagger', 'parser', 'ner']\nThis document is 5 tokens long.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nfrom spacy.matcher import PhraseMatcher\nfrom spacy.tokens import Span\nnlp = spacy.load(\"en_core_web_sm\")\nanimals = [\"Golden Retriever\", \"cat\", \"turtle\", \"Rattus norvegicus\"]\nanimal_patterns = list(nlp.pipe(animals))\nprint(\"animal_patterns:\", animal_patterns)\nmatcher = PhraseMatcher(nlp.vocab)\nmatcher.add(\"ANIMAL\", None, *animal_patterns)\n\n# Define the custom component\ndef animal_component(doc):\n    # Apply the matcher to the doc\n    matches = matcher(doc)\n    # Create a Span for each match and assign the label \"ANIMAL\"\n    spans = [Span(doc, start, end, label=\"ANIMAL\") for match_id, start, end in matches]\n    # Overwrite the doc.ents with the matched spans\n    doc.ents = spans\n    return doc\n\n# Add the component to the pipeline after the \"ner\" component\nnlp.add_pipe(animal_component, after=\"ner\")\nprint(nlp.pipe_names)\n\n# Process the text and print the text and label for the doc.ents\ndoc = nlp(\"I have a cat and a Golden Retriever\")\nprint([(ent.text, ent.label_) for ent in doc.ents])","execution_count":8,"outputs":[{"output_type":"stream","text":"animal_patterns: [Golden Retriever, cat, turtle, Rattus norvegicus]\n['tagger', 'parser', 'ner', 'animal_component']\n[('cat', 'ANIMAL'), ('Golden Retriever', 'ANIMAL')]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom attributes and Property extensions\n\nfrom spacy.lang.en import English\nfrom spacy.tokens import Token\n\nnlp = English()\n\n# Register the Token extension attribute \"is_country\" with the default value False\nToken.set_extension(\"is_country\", default=False)\n\n# Process the text and set the is_country attribute to True for the token \"Spain\"\ndoc = nlp(\"I live in Spain.\")\ndoc[3]._.is_country = True\n\n# Print the token text and the is_country attribute for all tokens\nprint([(token.text, token._.is_country) for token in doc])","execution_count":9,"outputs":[{"output_type":"stream","text":"[('I', False), ('live', False), ('in', False), ('Spain', True), ('.', False)]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.lang.en import English\nfrom spacy.tokens import Token\n\nnlp = English()\n# Define the getter function that takes a token and returns its reversed text\ndef get_reversed(token):\n    return token.text[::-1]\n# Register the Token property extension \"reversed\" with the getter get_reversed\nToken.set_extension(\"reversed\", getter=get_reversed)\n\n# Process the text and print the reversed attribute for each token\ndoc = nlp(\"All generalizations are false, including this one.\")\nfor token in doc:\n    print(\"reversed:\", token._.reversed)","execution_count":11,"outputs":[{"output_type":"stream","text":"reversed: llA\nreversed: snoitazilareneg\nreversed: era\nreversed: eslaf\nreversed: ,\nreversed: gnidulcni\nreversed: siht\nreversed: eno\nreversed: .\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.lang.en import English\nfrom spacy.tokens import Doc\n\nnlp = English()\n\n# Define the getter function\ndef get_has_number(doc):\n    # Return if any of the tokens in the doc return True for token.like_num\n    return any(token.like_num for token in doc)\n\n\n# Register the Doc property extension \"has_number\" with the getter get_has_number\nDoc.set_extension(\"has_number\", getter=get_has_number)\n\n# Process the text and check the custom has_number attribute\ndoc = nlp(\"The museum closed for five years in 2012.\")\nprint(\"has_number:\", doc._.has_number)","execution_count":12,"outputs":[{"output_type":"stream","text":"has_number: True\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling and Performance\n\n# docs = list(nlp.pipe(LOTS_OF_TE))\n# only tokenizer\n# nlp.make_doc\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading json data\n# import json\n# with open(\"exercises/en/tweets.json\") as f:\n#     TEXTS = json.loads(f.read())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ntext = (\n    \"Chick-fil-A is an American fast food restaurant chain headquartered in \"\n    \"the city of College Park, Georgia, specializing in chicken sandwiches.\"\n)\n# Disable the tagger and parser\nwith nlp.disable_pipes(\"tagger\", \"parser\"):\n    # Process the text\n    doc = nlp(text)\n    # Print the entities in the doc\n    print(doc.ents)","execution_count":13,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid character in identifier (<ipython-input-13-6767b5109d0c>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-6767b5109d0c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    â€‹\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}