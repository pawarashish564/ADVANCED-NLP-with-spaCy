{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Advanced NLP with spaCy\n## Chapter 1\n> Introduction to spaCy","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing spaCy\n# also there are packages for other languages like German, Spanish\n\n# Import the German language class\n# from spacy.lang.de import German\n\n# Import the Spanish language class\n# from spacy.lang.es import Spanish\n\n# Create the nlp object\nfrom spacy.lang.en import English\nnlp = English()\nnlp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# when we process any data from this nlp object spacy creates doc object (documentation) .\n# Doc object contains tokens \ndoc = nlp(\"hello world!\")\nfor token in doc:\n    print(token.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to get token at specific index you can use doc[1]\ntoken1 = doc[0]\ntoken1.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# span is just group of two or more tokens in doc \n# we can use list comprehensions to create span\nspan = doc[1:3]\nspan.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lexical Attributes\ndoc = nlp(\"It cost $5 dollers\")\nprint(\"index : \",[token.i for token in doc])\nprint(\"token text : \",[token.text for token in doc])\n\n\nprint(\"is_alpha : \",[token.is_alpha for token in doc])\nprint(\"is_punctuation : \",[token.is_punct for token in doc])\nprint(\"is_num : \",[token.like_num for token in doc])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process the text\ndoc = nlp(\n    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n    \"Now less than 4% are.\"\n)\n\n# Iterate over the tokens in the doc\nfor token in doc:\n    # Check if the token resembles a number\n    if token.like_num:\n        # Get the next token in the document\n        next_token = doc[token.i+1]\n        # Check if the next token's text equals \"%\"\n        if next_token.text == \"%\":\n            print(\"Percentage found:\", token.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# statistical models\n# it enables spacy to predict POS, named entities, syntanctic dependencies\n\n# en_core_web_sm -> small package has all the capabilies based on web text\n# this pre-trained model package can be download using spacy download command\n# python -m spacy download en_core_web_sm \n\nimport spacy\nnlp = spacy.load('en_core_web_sm')\n# this package contains binary weights for spacy to make predictions, vocabulary and meta information\n# (language and pipeline)\nnlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = nlp(\"she ate the pizza.\")\n# In spacy , attributes returns string ends with _\nfor token in doc:\n    print(token,token.pos_)\n# attribute without the _ returns int (id value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dependency label scheme\nfor token in doc:\n    print(token,token.pos_, token.dep_, token.head.text)\n    # head is like the parent token the current token attached to","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If you don't any thing in spacy just use spacy explain\nspacy.explain(\"det\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = nlp(\"Apple is looking at buying UK startup for $1 billion .\")\n# for named entities in text \nfor entities in doc.ents:\n    print(entities.text, entities.label_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spacy.explain(\"GPE\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Rule Based Matching\n# spacy matcher works on not only on strings also on docs\n# we use dictionaries to specify the  pattern\n\nfrom spacy.matcher import Matcher\n\nmatcher = Matcher(nlp.vocab)\n\n# List of dicts per token\n# Match exact tokens\n# pattern = [{\"TEXT\":\"iphone\"}]\n\n#match lexical attributes\n# pattern = [{\"LOWER\":\"iphone\"}]\n\n#match any token attributes\n# pattern = [{\"LEMMA\":\"buy\"},{\"POS\":'NOUN'}]\n\n# optional\n# pattern = [{\"LEMMA\":\"buy\",\"OP\":\"?\"},{\"POS\":'NOUN'}]\n# ! negate ,\n# ? 0/1 \n# + 1 or many \n# * zero or many\npattern = [{\"TEXT\":\"iphone\"},{\"TEXT\":\"X\"}]\n\nmatcher.add(\"IPHONE_Pattern\",None, pattern)\n\ndoc = nlp(\"Upcoming iphone X release date is leaked\")\n\nmatches = matcher(doc)\n\nfor match_id, start , end in matches:\n    matched_span = doc[start:end]\n    print(matched_span.text)\n    \nmatches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = nlp(\n    \"After making the iOS update you won't notice a radical system-wide \"\n    \"redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of \"\n    \"iOS 11's furniture remains the same as in iOS 10. But you will discover \"\n    \"some tweaks once you delve a little deeper.\"\n)\n\n# Write a pattern for full iOS versions (\"iOS 7\", \"iOS 11\", \"iOS 10\")\npattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n\n# Add the pattern to the matcher and apply the matcher to the doc\nmatcher.add(\"IOS_VERSION_PATTERN\", None, pattern)\nmatches = matcher(doc)\nprint(\"Total matches found:\", len(matches))\n\n# Iterate over the matches and print the span text\nfor match_id, start, end in matches:\n    print(\"Match found:\", doc[start:end].text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to get noun chunks \n# nouns = list(doc.noun_chunks)\n\n# to get sentences from the doc \n# list(doc.sents)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = nlp(\"Apple is looking at buying UK startup for $1 billion .\")\nspacy.displacy.render(doc, style='ent',jupyter=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lemmatization\nfor token in doc:\n    print(token.text, token.lemma_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependency Parser Visualization\nspacy.displacy.render(doc, style='dep',jupyter=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}